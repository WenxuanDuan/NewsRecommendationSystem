import numpy as np
from sklearn.model_selection import KFold
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from document import load_and_preprocess_documents, document_to_w2v
from util import compute_metrics, plot_confusion_matrix, plot_cross_validation, print_classification_results

def main():
    print("ğŸ“Œ Loading and Preprocessing Dataset...\n")
    data_dir = "../data/bbc/"
    documents, labels = load_and_preprocess_documents(data_dir)

    # **ğŸ“Œ å¤„ç† labels**
    unique_labels = sorted(set(labels))
    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}
    index_to_label = {idx: label for label, idx in label_to_index.items()}
    y = np.array([label_to_index[label] for label in labels])

    # **ğŸ“Œ è®¡ç®— TF-IDF ç‰¹å¾**
    print("\nğŸ“Œ Training TF-IDF model...\n")
    vectorizer = TfidfVectorizer()
    X_tfidf = vectorizer.fit_transform(documents)

    # **ğŸ“Œ è®¡ç®— Word2Vec ç‰¹å¾**
    print("\nğŸ“Œ Computing Word2Vec features...\n")
    X_w2v = np.array([document_to_w2v(doc) for doc in documents])

    # **ğŸ“Œ 10-Fold äº¤å‰éªŒè¯**
    print("\nğŸ“Œ Running 10-Fold Cross Validation...\n")
    kf = KFold(n_splits=10, shuffle=True, random_state=42)

    # ğŸ”¹ Naive Bayes
    nb_accuracies, nb_conf_mat = [], np.zeros((len(unique_labels), len(unique_labels)), dtype=int)

    # ğŸ”¹ kNN
    knn_accuracies, knn_conf_mat = [], np.zeros((len(unique_labels), len(unique_labels)), dtype=int)

    for fold, (train_idx, test_idx) in enumerate(kf.split(X_tfidf), 1):
        print(f"ğŸ”¹ Fold {fold}/10")

        # **ğŸ“Œ åˆ’åˆ†è®­ç»ƒé›† & æµ‹è¯•é›†**
        X_train_tfidf, X_test_tfidf = X_tfidf[train_idx], X_tfidf[test_idx]
        X_train_w2v, X_test_w2v = X_w2v[train_idx], X_w2v[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        # **ğŸ“Œ è®­ç»ƒ Naive Bayes**
        nb_model = MultinomialNB()
        nb_model.fit(X_train_tfidf, y_train)
        y_pred_nb = nb_model.predict(X_test_tfidf)

        # **ğŸ“Œ è®¡ç®— Naive Bayes è¯„ä¼°æŒ‡æ ‡**
        conf_mat_nb, report_nb, accuracy_nb = compute_metrics(y_test, y_pred_nb, unique_labels, index_to_label)
        nb_accuracies.append(accuracy_nb)
        nb_conf_mat += conf_mat_nb

        # **ğŸ“Œ è®­ç»ƒ kNN**
        knn_model = KNeighborsClassifier(n_neighbors=5, metric="cosine")  # ä½¿ç”¨ä½™å¼¦è·ç¦»
        knn_model.fit(X_train_w2v, y_train)
        y_pred_knn = knn_model.predict(X_test_w2v)

        # **ğŸ“Œ è®¡ç®— kNN è¯„ä¼°æŒ‡æ ‡**
        conf_mat_knn, report_knn, accuracy_knn = compute_metrics(y_test, y_pred_knn, unique_labels, index_to_label)
        knn_accuracies.append(accuracy_knn)
        knn_conf_mat += conf_mat_knn

        print(f"âœ… Naive Bayes Accuracy: {accuracy_nb:.4f}, kNN Accuracy: {accuracy_knn:.4f}\n")

    # **ğŸ“Œ æ‰“å°æœ€ç»ˆç»“æœ**
    print("\nğŸ“Œ Final Classification Report (Naive Bayes):")
    print_classification_results(nb_conf_mat, nb_accuracies, unique_labels)

    print("\nğŸ“Œ Final Classification Report (kNN):")
    print_classification_results(knn_conf_mat, knn_accuracies, unique_labels)

    # **ğŸ“Œ ç”»å›¾**
    plot_cross_validation(nb_accuracies, title="Naive Bayes 10-Fold Accuracy")
    plot_cross_validation(knn_accuracies, title="kNN 10-Fold Accuracy")
    plot_confusion_matrix(nb_conf_mat, unique_labels, title="Naive Bayes Confusion Matrix")
    plot_confusion_matrix(knn_conf_mat, unique_labels, title="kNN Confusion Matrix")

if __name__ == "__main__":
    main()
